{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaOq7btTB/91fh35h8PGxY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashu-94/POWER_BI_DASHBOARD_SQL_PROJECTS_OCTOBER/blob/main/Rag_Agent_With_FallBach_Mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries for LangChain and Google Generative AI\n",
        "!pip install -q langchain langchain-google-genai google-generativeai tiktoken langchain-community\n",
        "!pip install langchain langchain-google-genai google-generativeai tiktoken faiss-cpu huggingface_hub langchain-community langgraph"
      ],
      "metadata": {
        "id": "ImxkvdfTL06D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9469142-8d4d-4cc8-a1c5-ae6f9e30c96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.35)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.26.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.184.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.2)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.0)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.11.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RAG-Agent with fall back mechanism"
      ],
      "metadata": {
        "id": "eYmjCozLOLRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS#vector db\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults#lightweight wrapper\n",
        "import google.generativeai as genai\n",
        "from google.api_core.exceptions import ResourceExhausted\n",
        "from langchain.docstore.document import Document\n",
        "import os\n",
        "import time\n",
        "import uuid"
      ],
      "metadata": {
        "id": "Dj-G2E28L09L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_api_key=\"AIzaSyAH6UL-2STbDtz4mbAnaIV1kuplyL5Icg8\"\n",
        "genai.configure(api_key=gemini_api_key)\n",
        "Tavily_api_key=\"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\"\n",
        "os.environ[\"TAVILY_API_KEY\"]=\"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\"\n",
        "search_tool=TavilySearchResults(max_results=5)\n",
        "\n",
        "#initialize LLM\n",
        "#model= ChatGoogleGenerativeAI(\n",
        " #   model=\"models/gemini-2.0-flash\",\n",
        "  #  google_api_key=gemini_api_key,\n",
        "   # temperature=0,\n",
        "    #max_output_tokens=512\n"
      ],
      "metadata": {
        "id": "Lqv1f1auL1Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_text=\"\"\"\n",
        "Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\n",
        "sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, positionwise fully connected feed-forward network. We employ a residual connection [11] around each of\n",
        "the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\n",
        "LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\n",
        "itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\n",
        "layers, produce outputs of dimension dmodel = 512.\n",
        "Decoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two\n",
        "sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\n",
        "attention over the output of the encoder stack. Similar to the encoder, we employ residual connections\n",
        "around each of the sub-layers, followed by layer normalization. We also modify the self-attention\n",
        "sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\n",
        "masking, combined with fact that the output embeddings are offset by one position, ensures that the\n",
        "predictions for position i can depend only on the known outputs at positions less than i.\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "wJ1ZAgY0L1HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chunking(passing data in paragraph wise)"
      ],
      "metadata": {
        "id": "YhpEJMgzL1Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#overlap - chunking\n",
        "def chunk_text(text, chunk_size=500):\n",
        "  chunks = []\n",
        "  for i in range(0, len(text), chunk_size):\n",
        "    chunk = text[i:i+chunk_size]\n",
        "    if len(chunk)>200:\n",
        "      chunks.append(chunk)\n",
        "  return chunks or [text]"
      ],
      "metadata": {
        "id": "sWL6Q8akUkSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tavily api -> ask -> return answer -> error -> stop ? api try again?"
      ],
      "metadata": {
        "id": "Ku_jMI_qPmzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_with_retry(text, max_retries = 3):\n",
        "  if not text.strip():\n",
        "    return \"Empty Content\"\n",
        "  prompt = f\"Summarize concisely:\\n{text}\"\n",
        "  for attempt in range(max_retries):\n",
        "    try:\n",
        "      response = model.generate_content(prompt)\n",
        "      return response.text.strip() if response.text else \"No summary generated\"\n",
        "    except ResourceExhausted:\n",
        "      if attempt < max_retries - 1:\n",
        "        wait_time = 2 ** attempt\n",
        "        print(f\"Rate limit hit, wairting {wait_time} seconds...\")\n",
        "        time.sleep(wait_time)\n",
        "      else:\n",
        "        return \"Error: API quota excedded\"\n",
        "  return \"Error: Failed after retries\""
      ],
      "metadata": {
        "id": "BTy-vipMPm2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_store(texts):\n",
        "  summaries = [summarize_with_retry(text) for text in texts]\n",
        "\n",
        "  valid_summaries = [s for s in summaries if not s.startswith(\"Error\")]\n",
        "\n",
        "  if not valid_summaries:\n",
        "    raise ValueError(\"No valid summaries generated for vectorstore\")\n",
        "\n",
        "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "  documents = [Document(page_content=summary, metadata={\"id\":str(uuid.uuid4())}) for summary in valid_summaries]\n",
        "\n",
        "  return FAISS.from_documents(documents, embeddings)\n"
      ],
      "metadata": {
        "id": "5C39fmFfPm5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(query, vector_store):\n",
        "  print(f\"Question : {query}\")\n",
        "\n",
        "  if vector_store:\n",
        "    try:\n",
        "      docs_with_scores = vector_store.similarity_search_with_score(query, k=3)\n",
        "      print(f\"docs_with_scores : {docs_with_scores}\")\n",
        "      #here -debug from here\n",
        "      relevant_docs = [doc for doc, score in docs_with_scores if score < 0.8]\n",
        "      if relevant_docs:\n",
        "        context = \"\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "        prompt = f\"answer based on this context : \\n{context}\\n\\nQuestion:{query}\"\n",
        "        response = model.generate_content(prompt)\n",
        "        if response.text:\n",
        "          return {\"answer\":response.text.strip(), \"source\":\"internal document\"}\n",
        "    except Exception as e:\n",
        "      print(f\"RAG failed : {str(e)}\")\n",
        "  try:\n",
        "    search_results = search_tool.invoke({\"query\":query})\n",
        "    return {\"answer\": str(search_results), \"source\":\"internet search\"}\n",
        "  except Exception as e:\n",
        "    print(f\"Error : {str(e)}\")"
      ],
      "metadata": {
        "id": "2CFF7aFRPm8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  vector_store = None\n",
        "  try:\n",
        "    chunks = chunk_text(transformer_text)\n",
        "    vector_store = create_vector_store(chunks)\n",
        "    print(f\"Vector store created successfully\")\n",
        "  except Exception as e:\n",
        "    print(f\"Vector store creation failed\")\n",
        "    print(f\"Will use use internet search\")\n",
        "\n",
        "\n",
        "  questions = [\n",
        "      \"who is the pesident of India?\",\n",
        "      \"The decoder is also composed of a stack of how many identical layers.\"\n",
        "  ]\n",
        "\n",
        "  for question in questions:\n",
        "    result = answer_question(question, vector_store)\n",
        "    print(f\"Answer: {result['answer']}\")\n",
        "    print(f\"Source: {result['source']}\")"
      ],
      "metadata": {
        "id": "IRsTuLHhPm_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1WW2X0tPnC6",
        "outputId": "aea72faa-22b8-4994-d613-1e98906362c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store creation failed\n",
            "Will use use internet search\n",
            "Question : who is the pesident of India?\n",
            "Answer: [{'title': 'President of India - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/President_of_India', 'content': 'The president of India (ISO: Bhārata kē Rāṣṭrapati) is the head of state of the Republic of India. The president is the nominal head of the executive, the first citizen of the country, and the supreme commander of the Indian Armed Forces. Droupadi Murmu is the 15th and current president, having taken office on 25 July 2022. [...] | Government   President of India (List)   Droupadi Murmu   Vice President of India (List)   C. P. Radhakrishnan   Prime Minister of India (List)   Narendra Modi   Cabinet Secretary   T. V. Somanathan   Ministries   + Ministers  Departments and Agencies   + Secretaries | [...] January 1950,:\\u200a26 making India a republic.:\\u200a9 The offices of monarch and governor-general were replaced by the new office of President of India, with Rajendra Prasad as its first incumbent.:\\u200a1 India retained its Commonwealth membership per the London Declaration, recognising The King as \"the symbol of the free association of its independent member nations and as such the Head of the Commonwealth.\"', 'score': 0.8319231}, {'title': \"List of Indian Presidents – 1950 to 2022 - BYJU'S\", 'url': 'https://byjus.com/govt-exams/list-indian-presidents/', 'content': 'The Constitution of India was adopted on 26th November 1949 (It came into force on 26th January 1950) and Dr Rajendra Prasad was elected as the first constitutional head of the state, the President of India. \\n\\nRam Nath Kovind, the 14th President of India, completed his term in July 2022. Though he was eligible, he did not contest for re-election. As a result, Draupadi Murmu in July 2022, became the 15th Indian President, appointed by the electoral college. [...] | Avul Pakir Jainulabdeen Abdul Kalam | 25 July 2002 – 25 July 2007 |  He played a leading role in the development of India’s ballistic missile and nuclear weapons programs.  He was also a Bharat Ratna recipient. |\\n| Pratibha Patil | 25 July 2007 – 25 July 2012 |  She was the first woman president of India. |\\n| Pranab Mukherjee | 25 July – 25 July 2017 |  He was awarded the best Parliamentary Award in 1997.  He also received Padma Vibhushan in 2008 | [...] | Ram Nath Kovind | 25 July 2017 – 25 July 2022 |  He served as the Governor of Bihar. |\\n| Draupadi Murmu | 25 July 2022 – Incumbent |  She has served as the governor of Jharkhand previously. |', 'score': 0.7606688}, {'title': 'About Us - The Office and Residence of the President of India', 'url': 'http://www.rashtrapatibhavan.gov.in/about-us', 'content': \"Feedback\\n Sitemap\\n FAQs\\n RTI\\n Skip to Main Content\\n\\n Screen Reader Access\\n A+ A A -\\n\\n#### राष्ट्रपति भवनRashtrapati Bhavan\\n\\n##### About Us\\n\\n### About thePresident's Secretariat\\n\\n\\uf104 BACK)\\n\\nThe President of India is the head of state of the Republic of India. The President is the nominal head of the executive, the first citizen of the country, as well as the commander-in-chief of the Indian Armed Forces. Smt. Droupadi Murmu is the 15th and current President, having taken office from 25 July 2022.\", 'score': 0.7373288}, {'title': 'Press Release - The President of India', 'url': 'http://www.presidentofindia.gov.in/press-release', 'content': 'Feedback\\n Sitemap\\n Skip to Main Content\\n\\n Screen Reader Access\\n A+ A A -\\n\\n#### Smt. Droupadi MurmuThe President of India\\n\\n# Press Release', 'score': 0.7089592}, {'title': 'Droupadi Murmu | Life, Education, Career, & Facts | Britannica', 'url': 'https://www.britannica.com/biography/Droupadi-Murmu', 'content': 'Bundle Britannica Premium and Kids for the ultimate resource destination.\\n\\n## President of India [...] In June 2022 the National Democratic Alliance (NDA), a political alliance led by the BJP, nominated Murmu for the presidency of India. India’s president is indirectly elected by an electoral college comprising the elected members of both houses of the federal parliament and the elected members of the legislative assemblies of India’s 28 states as well as the union territories of Delhi, Puducherry, and Jammu and Kashmir. Murmu defeated Yashwant Sinha, a candidate chosen by the parties in', 'score': 0.7065353}]\n",
            "Source: internet search\n",
            "Question : The decoder is also composed of a stack of how many identical layers.\n",
            "Answer: [{'title': '3.1 Encoder and Decoder Stacks · GitBook', 'url': 'https://windmissing.github.io/NLP-important-papers/AIAYN/EncoderAndDecoderStacks.html', 'content': 'Decoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This [...] Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, positionwise fully connected feed-forward network. We employ a residual connection  around each of the two sub-layers, followed by layer normalization . That is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself. To facilitate these [...] > [success]\\n\\n```\\nclass DecoderLayer(nn.Module): class DecoderLayer(nn.Module) \\'\\'\\' Compose with three layers \\'\\'\\'def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1): def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1)0.1def forward( self, dec_input, enc_output, slf_attn_mask=None, dec_enc_attn_mask=None): def forward( self, dec_input, enc_output, slf_attn_mask=None, dec_enc_attn_mask=None) return\\n```\\n\\n# results matching \"\"\\n\\n# No results matching \"\"', 'score': 0.9314689}, {'title': 'How Transformers Work: A Detailed Exploration of ... - DataCamp', 'url': 'https://www.datacamp.com/tutorial/how-transformers-work', 'content': 'These positional embeddings are then channeled into the first multi-head attention layer of the decoder, where the attention scores specific to the decoder’s input are meticulously computed.\\n\\n#### STEP 3 - Stack of Decoder Layers\\n\\nThe decoder consists of a stack of identical layers (6 in the original Transformer model). Each layer has three main sub-components:\\n\\n##### STEP 3.1 Masked Self-Attention Mechanism [...] However, both the encoder and the decoder are actually a stack with multiple layers (same number for each). All encoders present the same structure, and the input gets into each of them and is passed to the next one. All decoders present the same structure as well and get the input from the last encoder and the previous decoder.\\n\\nThe original architecture consisted of 6 encoders and 6 decoders, but we can replicate as many layers as we want. So let’s assume N layers of each. [...] In this approach, each dimension is represented by unique frequencies and offsets of the wave, with the values ranging from -1 to 1, effectively representing each position.\\n\\nImage by the author. Encoder’s workflow. Positional encoding.\\n\\n#### STEP 3 - Stack of Encoder Layers\\n\\nThe Transformer encoder consists of a stack of identical layers (6 in the original Transformer model).', 'score': 0.8338803}, {'title': 'Encoders and Decoders in Transformer Models', 'url': 'https://machinelearningmastery.com/encoders-and-decoders-in-transformer-models/', 'content': 'The encoder processes the input sequence (e.g., a sentence in the source language) into a contextual representation. It consists of a stack of identical layers, each containing a self-attention sublayer and a feed-forward sublayer. [...] The model has an “embeddings” layer to transform input token IDs into a vector space of dimension 768. The model also has a “pooler” layer at the end to transform the output before feeding it to a task-specific model head. The main body of the BERT model is the `BertEncoder` module, which is a stack of 12 architecturally identical `BertLayer` modules. There are multiple linear, layer norm, and dropout layers in each `BertLayer`. However, there is only one `BertAttention` module, in which the [...] The decoder follows a similar structure, processing the target sequence (e.g., a partial sentence in the target language). Each decoder layer contains three sublayers: self-attention, cross-attention, and feed-forward. The cross-attention sublayer is unique to the decoder, combining context from the encoder with the target sequence to generate the output.', 'score': 0.64826655}, {'title': 'The decoder stack in the Transformer model | by Sandaruwan Herath', 'url': 'https://medium.com/image-processing-with-python/the-decoder-stack-in-the-transformer-model-20db967150a7', 'content': 'The decoder stack in the Transformer model, much like its encoder counterpart, consists of several layers, each featuring three main components. These are a multi-headed masked attention mechanism, a multi-headed attention mechanism, and a fully connected feedforward network. This structure is consistently repeated across all layers of the decoder.\\n\\n### The Decoder Architecture [...] 3. Position-wise Feedforward Networks: Each layer also includes a feedforward neural network, which applies the same weights to each position separately, processing the data identically across the sequence. This uniform treatment helps maintain consistency in data handling. [...] The decoder in the Transformer model mirrors the encoder with layers that are stacked upon each other, but with additional components tailored for generating predictions:', 'score': 0.5889134}, {'title': 'The Decoder. This is the seventh article in The… | by Hunter Phillips', 'url': 'https://medium.com/@hunter-j-phillips/the-decoder-8882c33de69a', 'content': '## Decoder Stack\\n\\nTo exploit the benefits of the multi-head attention sublayers, input tokens are passed through a stack of decoder layers at a time, which can be seen in the image above. This is notated as Nx in the image at the beginning of the article. [...] class Decoder(nn.Module):  def __init__(self, vocab_size: int, d_model: int, n_layers: int,                n_heads: int, d_ffn: int, dropout: float = 0.1):    \"\"\"    Args:        vocab_size:   size of the vocabulary        d_model:      dimension of embeddings        n_layers:     number of encoder layers        n_heads:      number of heads        d_ffn:        dimension of feed-forward network        dropout:      probability of dropout occurring    \"\"\"    super().__init__()    # create [...] n_layers encoders     self.layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ffn, dropout)                                 for layer in range(n_layers)])        self.dropout = nn.Dropout(dropout)    # set output layer    self.Wo = nn.Linear(d_model, vocab_size)      def forward(self, trg: Tensor, src: Tensor, trg_mask: Tensor, src_mask: Tensor):    \"\"\"    Args:        trg:          embedded sequences                (batch_size, trg_seq_length, d_model)        src:          encoded', 'score': 0.5513086}]\n",
            "Source: internet search\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model context protocol"
      ],
      "metadata": {
        "id": "BZ0Bqm8kPnGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z7tmWswAPnJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPPpWPTCPnM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}